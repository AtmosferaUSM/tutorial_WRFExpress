{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction to Using WRFExpress for Running WRF on AWS WRFExpress is designed to streamline the process of running Weather Research and Forecasting (WRF) models on AWS clusters. This tool simplifies complex configurations and automates various steps, making it accessible even to those without deep technical expertise. Here\u2019s how you can utilize WRFExpress to get started with your WRF simulations. Website Interface The web interface of WRFExpress allows you to easily define your simulation domain by selecting an area on an interactive map. Here\u2019s a step-by-step guide on how to use it: Access the Website: Navigate to the WRFExpress website and log in with your credentials. Select a Domain: Use the interactive map to draw rectangles defining your simulation domains. You can create multiple nested domains by drawing new rectangles within existing ones. Configuration Settings: On the right side of the screen, fill in the necessary configuration details: Orcid ID : Enter your ORCID ID. API Token : Provide your API token. Start Date and End Date : Specify the start and end dates for your simulation period. Time Interval : Set the time interval for data points (e.g., 6 hours). DX and DY : Specify the grid spacing for your simulation. Update Configuration: After filling in the details, click on \"Update Configuration\" to save your settings. Generate Namelist: Click on \"Generate Namelist\" to create the namelist.wps file, which is essential for running WRF. Generate Download Data Code: Click on \"Generate Download Data Code\" to get the Python script for downloading necessary data files. Running WRF on AWS Cluster After configuring your simulation domain and generating necessary files, follow these steps to run WRF on the AWS cluster: Go to WRFExpress.com and log in. After entering the necessary info and clicking on the \u201dUpdate Configuration\u201d button, copy the namelist text by clicking on the \u201cGenerate Namelist\u201d and \u201cCopy to Clipboard\u201d buttons. On AWS Parallel Cluster WRF-P2 , paste the copied namelist in the terminal and press Enter. On WRFExpress, click \u201cGenerate Download Data Code\u201d and copy the info by clicking the \u201cCopy to Clipboard\u201d button at the bottom. Paste the text in the WRF-P2 terminal and press enter. Directory structure of the WRF model setup on AWS. Run the command: python3 main.py Choose 1 for \u201dEnter the step number.\u201d Choose 1 for the node number. Choose 2 for the tasks per node. Choose \u201dHourly\u201d for the NC file output resolution. Wait for the run to complete. You can check the progress by opening another shell and typing squeue in the terminal. You can see the progress when the model has started running. Note that if you need to rerun the model using the same config, you can call main.py again and choose step 4. When the run is complete, you can see the data on the WRFExpress website after refreshing the screen. Download the data by selecting the file, files are named with the time (e.g., 2019-07-23 _16-05-18) when the run was complete, clicking the \u201cCopy AWS Commands\u201d and pasting the code in the terminal. Key Features of the Python Script Shell Command Execution: Automates the execution of multiple WRF-related shell scripts. S3 Integration: Uploads simulation outputs to an S3 bucket and generates a presigned URL for easy download. Progress Monitoring: Uses the rich library to display real-time progress of script execution and job queue status. Error Handling: Provides informative logs for troubleshooting any issues that arise during execution. By following these steps, WRFExpress simplifies the setup and execution of WRF simulations on AWS, allowing users to focus more on their research and less on the technical complexities of the modeling process.","title":"Overview"},{"location":"#introduction-to-using-wrfexpress-for-running-wrf-on-aws","text":"WRFExpress is designed to streamline the process of running Weather Research and Forecasting (WRF) models on AWS clusters. This tool simplifies complex configurations and automates various steps, making it accessible even to those without deep technical expertise. Here\u2019s how you can utilize WRFExpress to get started with your WRF simulations.","title":"Introduction to Using WRFExpress for Running WRF on AWS"},{"location":"#website-interface","text":"The web interface of WRFExpress allows you to easily define your simulation domain by selecting an area on an interactive map. Here\u2019s a step-by-step guide on how to use it: Access the Website: Navigate to the WRFExpress website and log in with your credentials. Select a Domain: Use the interactive map to draw rectangles defining your simulation domains. You can create multiple nested domains by drawing new rectangles within existing ones. Configuration Settings: On the right side of the screen, fill in the necessary configuration details: Orcid ID : Enter your ORCID ID. API Token : Provide your API token. Start Date and End Date : Specify the start and end dates for your simulation period. Time Interval : Set the time interval for data points (e.g., 6 hours). DX and DY : Specify the grid spacing for your simulation. Update Configuration: After filling in the details, click on \"Update Configuration\" to save your settings. Generate Namelist: Click on \"Generate Namelist\" to create the namelist.wps file, which is essential for running WRF. Generate Download Data Code: Click on \"Generate Download Data Code\" to get the Python script for downloading necessary data files.","title":"Website Interface"},{"location":"#running-wrf-on-aws-cluster","text":"After configuring your simulation domain and generating necessary files, follow these steps to run WRF on the AWS cluster: Go to WRFExpress.com and log in. After entering the necessary info and clicking on the \u201dUpdate Configuration\u201d button, copy the namelist text by clicking on the \u201cGenerate Namelist\u201d and \u201cCopy to Clipboard\u201d buttons. On AWS Parallel Cluster WRF-P2 , paste the copied namelist in the terminal and press Enter. On WRFExpress, click \u201cGenerate Download Data Code\u201d and copy the info by clicking the \u201cCopy to Clipboard\u201d button at the bottom. Paste the text in the WRF-P2 terminal and press enter. Directory structure of the WRF model setup on AWS. Run the command: python3 main.py Choose 1 for \u201dEnter the step number.\u201d Choose 1 for the node number. Choose 2 for the tasks per node. Choose \u201dHourly\u201d for the NC file output resolution. Wait for the run to complete. You can check the progress by opening another shell and typing squeue in the terminal. You can see the progress when the model has started running. Note that if you need to rerun the model using the same config, you can call main.py again and choose step 4. When the run is complete, you can see the data on the WRFExpress website after refreshing the screen. Download the data by selecting the file, files are named with the time (e.g., 2019-07-23 _16-05-18) when the run was complete, clicking the \u201cCopy AWS Commands\u201d and pasting the code in the terminal.","title":"Running WRF on AWS Cluster"},{"location":"#key-features-of-the-python-script","text":"Shell Command Execution: Automates the execution of multiple WRF-related shell scripts. S3 Integration: Uploads simulation outputs to an S3 bucket and generates a presigned URL for easy download. Progress Monitoring: Uses the rich library to display real-time progress of script execution and job queue status. Error Handling: Provides informative logs for troubleshooting any issues that arise during execution. By following these steps, WRFExpress simplifies the setup and execution of WRF simulations on AWS, allowing users to focus more on their research and less on the technical complexities of the modeling process.","title":"Key Features of the Python Script"},{"location":"troubleshooting/","text":"Steps To Monitor and Troubleshoot You can check the progress by opening another shell and typing squeue in the terminal. You can see the progress when the model has started running. Monitoring the Model Open another shell on the AWS ParallelCluster page. Navigate to /shared/scratch/WRF/run . Troubleshooting Errors If there is an error, type tail rsl.error.0000 to show the error message.","title":"Monitoring and Troubleshooting"},{"location":"troubleshooting/#steps-to-monitor-and-troubleshoot","text":"You can check the progress by opening another shell and typing squeue in the terminal. You can see the progress when the model has started running.","title":"Steps To Monitor and Troubleshoot"},{"location":"troubleshooting/#monitoring-the-model","text":"Open another shell on the AWS ParallelCluster page. Navigate to /shared/scratch/WRF/run .","title":"Monitoring the Model"},{"location":"troubleshooting/#troubleshooting-errors","text":"If there is an error, type tail rsl.error.0000 to show the error message.","title":"Troubleshooting Errors"},{"location":"web/","text":"User Guide for Website Environment Overview This guide provides detailed step-by-step instructions on how to use the website for generating namelist files and downloading GFS data. By following these steps, users can efficiently set up their environment, configure their data, and prepare necessary files for their projects. Step 1: Setting Up the Environment - Upon accessing the website, users will see an interactive map interface. This map is used to define the area of interest for data configuration. - Users need to click on the square icon located at the top of the page. This icon allows you to draw a rectangular selection on the map. - To draw a square, click and hold the mouse button on the map, then drag to create the desired area. Release the mouse button to complete the selection. - Alternatively, users can use the hand tool to resize the square by clicking on the edges or corners of the drawn area and dragging to adjust the size. The map can also be moved by clicking and dragging the map itself. Step 2: Choosing the Grid Ratio - After drawing the desired area on the map, a prompt will appear asking for the grid ratio. - The grid ratio defines the resolution of the grid for the selected area. For accurate data configuration, the first grid ratio should always be set to 1. - Enter the value 1 in the prompt and click OK to confirm. - This step ensures that the base grid is set correctly, which is essential for subsequent configurations. Step 3: Generating the Namelist - Users can generate a namelist file by clicking on the \"Generate Namelist\" button located in the \"Data Download\" section. - The website will automatically generate the namelist file based on the selected area and grid ratio. - Once generated, the namelist file content will be displayed in a popup window. - Copy the generated namelist by clicking the \"Copy to Clipboard\" button. - Paste the copied namelist into the appropriate location on your cluster. This file is essential for running WRF models as it contains configuration settings. Step 4: Downloading GFS Files - Similar to generating the namelist, users can download GFS files by clicking on the relevant button in the \"Data Download\" section. - The website will generate Python code required to download the GFS data files. - This code will be displayed in a popup window. - Copy the provided Python code by clicking the \"Copy to Clipboard\" button. - Paste the copied code into your Python environment or script to download the necessary GFS data files. - Ensure that you have the required permissions and internet access to download the data from the specified URLs. Step 5: Confirmation of Copied Files - After copying the namelist and GFS Python code, a confirmation message will appear. - This message indicates that the files have been successfully copied and are ready to use. - The confirmation ensures that users can proceed with their workflow, knowing that the necessary files are prepared for the next steps. - Users should verify that the copied files are correctly placed in their designated locations on the cluster or local environment. Step 6: Downloading Data from S3 - To download the data from S3, users can view the list of available datasets stored on Amazon S3. - On the right-hand side of the interface, there is a \"Data Download\" section that lists available datasets. - Scroll through the list and select the required dataset by clicking on it. The selection will highlight the chosen dataset. - Once a dataset is selected, the website will generate a temporary access key. - This temporary access key can be used to download the data directly from the S3 bucket using a Linux or Mac terminal. - Copy the provided access key and use it with commands like aws s3 cp to download the entire folder containing the dataset. - This step allows users to easily transfer data from the cloud to their local or cluster environment for further processing. By following these detailed steps, users can efficiently navigate the website, configure their data, and prepare the necessary files for their meteorological and environmental projects.","title":"Website"},{"location":"web/#user-guide-for-website-environment","text":"","title":"User Guide for Website Environment"},{"location":"web/#overview","text":"This guide provides detailed step-by-step instructions on how to use the website for generating namelist files and downloading GFS data. By following these steps, users can efficiently set up their environment, configure their data, and prepare necessary files for their projects.","title":"Overview"},{"location":"web/#step-1-setting-up-the-environment","text":"- Upon accessing the website, users will see an interactive map interface. This map is used to define the area of interest for data configuration. - Users need to click on the square icon located at the top of the page. This icon allows you to draw a rectangular selection on the map. - To draw a square, click and hold the mouse button on the map, then drag to create the desired area. Release the mouse button to complete the selection. - Alternatively, users can use the hand tool to resize the square by clicking on the edges or corners of the drawn area and dragging to adjust the size. The map can also be moved by clicking and dragging the map itself.","title":"Step 1: Setting Up the Environment"},{"location":"web/#step-2-choosing-the-grid-ratio","text":"- After drawing the desired area on the map, a prompt will appear asking for the grid ratio. - The grid ratio defines the resolution of the grid for the selected area. For accurate data configuration, the first grid ratio should always be set to 1. - Enter the value 1 in the prompt and click OK to confirm. - This step ensures that the base grid is set correctly, which is essential for subsequent configurations.","title":"Step 2: Choosing the Grid Ratio"},{"location":"web/#step-3-generating-the-namelist","text":"- Users can generate a namelist file by clicking on the \"Generate Namelist\" button located in the \"Data Download\" section. - The website will automatically generate the namelist file based on the selected area and grid ratio. - Once generated, the namelist file content will be displayed in a popup window. - Copy the generated namelist by clicking the \"Copy to Clipboard\" button. - Paste the copied namelist into the appropriate location on your cluster. This file is essential for running WRF models as it contains configuration settings.","title":"Step 3: Generating the Namelist"},{"location":"web/#step-4-downloading-gfs-files","text":"- Similar to generating the namelist, users can download GFS files by clicking on the relevant button in the \"Data Download\" section. - The website will generate Python code required to download the GFS data files. - This code will be displayed in a popup window. - Copy the provided Python code by clicking the \"Copy to Clipboard\" button. - Paste the copied code into your Python environment or script to download the necessary GFS data files. - Ensure that you have the required permissions and internet access to download the data from the specified URLs.","title":"Step 4: Downloading GFS Files"},{"location":"web/#step-5-confirmation-of-copied-files","text":"- After copying the namelist and GFS Python code, a confirmation message will appear. - This message indicates that the files have been successfully copied and are ready to use. - The confirmation ensures that users can proceed with their workflow, knowing that the necessary files are prepared for the next steps. - Users should verify that the copied files are correctly placed in their designated locations on the cluster or local environment.","title":"Step 5: Confirmation of Copied Files"},{"location":"web/#step-6-downloading-data-from-s3","text":"- To download the data from S3, users can view the list of available datasets stored on Amazon S3. - On the right-hand side of the interface, there is a \"Data Download\" section that lists available datasets. - Scroll through the list and select the required dataset by clicking on it. The selection will highlight the chosen dataset. - Once a dataset is selected, the website will generate a temporary access key. - This temporary access key can be used to download the data directly from the S3 bucket using a Linux or Mac terminal. - Copy the provided access key and use it with commands like aws s3 cp to download the entire folder containing the dataset. - This step allows users to easily transfer data from the cloud to their local or cluster environment for further processing. By following these detailed steps, users can efficiently navigate the website, configure their data, and prepare the necessary files for their meteorological and environmental projects.","title":"Step 6: Downloading Data from S3"}]}